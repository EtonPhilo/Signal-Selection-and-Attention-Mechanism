\documentclass[12pt]{ctexart}  % ctexart 支持中文排版

% 页面边距设置
\usepackage{geometry}
\geometry{left=3cm, right=3cm, top=2.5cm, bottom=2.5cm}

% 行距设置
\usepackage{setspace}
\onehalfspacing  % 设置为 1.5 倍行距

% 每段首行缩进
\usepackage{indentfirst}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{verbatim}
% 页眉页脚设置
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{信号选择与注意力机制}  
\rhead{周羿彤 24210160059}
\cfoot{\thepage}
\renewcommand{\abstractname}{}

% 论文封面信息
\title{\bfseries 信号选择与注意力机制\
\par\vspace{1em}
\large 全文总字数：约7560字}
\author{周羿彤}
\date{\today}

% 如果使用 BibLaTeX 和 gb7714-2015 规范（需自行安装相关宏包）
% \usepackage[backend=biber,style=gb7714-2015,sorting=none]{biblatex}
% \addbibresource{reference.bib}

\begin{document}

\maketitle
\ctexset{section={
        number=\chinese{section},
        aftername={、}
    },
    subsection={
        number=\arabic{subsection},
        aftername={. }
    }
}

\begin{abstract}
\noindent
{\bf{摘要：}}\ 刘易斯-斯基姆信号博弈有效地解释了信号作为一种初级的语言是如何产生的。在标准的信号博弈模型中，发送者和接收者都认可同一套信号，并在博弈过程中逐渐建立信号与状态、行为之间的联系。赫尔曼和范德鲁宁放弃接收者总能正确识别信号的假设，提出了“注意力博弈”来表征接收者通过学习正确分配注意力来识别信号的过程。笔者利用这一框架进一步讨论基于生物体注意力机制的信号博弈，研究接收者注意力分配不均以及不同特征的传输成功率导致的不对称性，解释注意力机制如何实现信号的选择，并指出这些选择如何提高信号交流的效率和稳健性。

\par\vspace{1em}
% 请在此处简要概述研究背景、目的、方法、结果及主要结论。（摘要中文字应力求语言精炼、结构清晰。）
\end{abstract}

\section*{引言}
% 在此部分介绍研究背景、选题依据、文献综述及论文结构安排等。
刘易斯-斯基姆信号博弈可以非常有效地解释简单的语言系统是如何通过演化产生。\cite{Lewis,Skyrms game,Skyrms info}但这一模型假设发送者与接收者都清楚无误地知道它们所采取的信号是什么。当发送者观察到特定的状态时，它会从公认的信号集合中选取信号并发送，而接收者总能在信号发出后注意到信号的发送并准确地识别它，然后根据该信号作出反应。这无疑是一个非常强的假设，很难想象现实世界中的动物们事先具有种群内部公认的信号集。当发送者意欲通过特定行为传递信号时，接收者很可能无法从中识别出作为信号的那一部分，因为它并不清楚信号可能是什么。因此，它完全有可能将无关的行为特征当作信号，而在下一次发送信号时，若发送者碰巧没有表现出这一行为特征，导致交流的失效。

赫尔曼（Daniel A. Herrmann）和范德鲁宁（Jacob VanDrunen）放弃了这一假设，并额外引入注意力机制来表征接收者识别信号的过程，这一新模型被他们称为“注意力博弈”（attention game）。\cite{attention}在注意力博弈中，接收者并不直接收到信号本身，而是收到一个由信号决定的特征向量，其中的各个分量表示接收者接收到的各类感觉刺激。接收者只会关注到其中一类特征，即特征向量中的一个向量，并依据此进行行动。因此，接收者实际上需要进行两次选择，首先它要选择关注哪类特征，其次它依据注意到的特征选择行动。这一额外的过程要求接收者不仅需要摸索出收到特征时的正确反应，还需要学会关注最能反映信号本身的特征。

特征作为信号与接收者之间的中继，给博弈过程引入了更多的变数。更多的特征可能会导致接收者更容易关注错误的部分，因而延缓信号系统建立的进程。但是，它也增强了信号博弈的解释力。在笔者看来，提出信号博弈的一个重要动机恰恰是去解释一个高效的交流模式是如何建立起来的。但标准的博弈模型只解释了一部分，即如果有确定的信号集，其中的信号如何与现实状态联系起来从而获得意义，而没有解释信号作为交流信息的载体是如何经过选择最终受到公认的。我们会注意到生物总是偏好某些信号，例如哺乳类动物常用气味标记领地、昆虫常用信息素进行交流，还有许多动物采用多模态信号，其接收涉及多种感官通道。在最广泛的意义上，发送者能够有意做出的举动或引发的事态都可以用作信号，为什么只有其中很小的一部分被广泛用作了信号？这意味着演化过程中不同的信号一定具有某种不对称性，导致种群总是收敛到由这些信号构成的信号系统中，而我将在本文讨论如何利用注意力机制引入的不对称性为这些问题提供解答。更具体一些，这些不对称性可以分为两类，一类是接收侧的不对称性，它来自接收者注意力资源分布不均；另一类则是发送侧的不对称性，它来自于由信号本身性质决定的发送成功率。

本文分为三节，我将在第一节简要介绍注意力博弈的动机、模型设定并阐释其基本思想。我还将以最简单的$2\times 2\times 2$模型为例，利用强化学习的演示特征数量的增加对信号博弈过程的影响。在第二节，我讨论接收侧的不对称性，展示发送者如何利用接收者本身的注意力资源的不对称性，发送合适的信息以提高信号交流的效率。我介绍了两种可能的机制，并通过数值模拟展示这两种机制如何使种群在博弈过程中逐渐增加某一类信号的使用率。在第三节，我讨论发送侧的不对称性，展示信号中各个特征传输成功率对信号博弈过程的影响。我发现了信号使用率与其携带信息之间的关联，并指出信号选择与其携带的信息量之间的关系。


\section{注意力博弈}

\subsection{模型设定}
设想一只在树顶眺望的猴子发现猎豹正在靠近它所在族群的栖息地，它通过大声的叫喊提醒同伴，但同伴会将它的行为的哪一部分理解为信号？它们所看到的是一只因惊恐而尖叫、上蹿下跳的猴子，信号究竟是叫声，还是这只猴子在树枝间跳跃的肢体动作，抑或是这两者的结合？我们可能会希望它们会将它的叫声理解为信号，因为类似的事件再次发生时，这只猴子或许不再因惊恐而上蹿下跳，也可能不在树顶，而它仍然会发出叫声。但问题远比这要复杂，因为也许这只猴子会用不同的叫声作为不同状况下的警报，而这些叫声具有不同的声学特征，例如不同的响度、频率和持续时长等，究竟何者能作为最具代表性的特征将不同警报区分开来还无从可知。我并不否认其他猴子能够注意到它的同伴作出的不寻常的举动，并因此决定采取行动，但它们并不天然地知道这一举动的哪一部分被用作信号，如果将错误的特征当作信号并只在看到这一特征时作出反应，它们将无法正确地应对环境的变化。因此，稳定地识别出信号要素的能力是信号系统得以形成的基础，而这一能力的建立并不平凡，它是需要解释的“奇迹”。

基于这一想法，赫尔曼（Daniel A. Herrmann）和范德鲁宁（Jacob VanDrunen）提出了注意力博弈。\cite{attention}它与标准的信号博弈模型没有太大的区别，同样有一定数量的自然状态、信号和行为。除此之外，注意力博弈引入了$l+1$个称为“特征”（feature）的集合$F_i$，表示接收者能够注意到的几类特征，其中的元素$f_i\in F_i$则表示具体的特征。每当发送者发出一个信号时，接收者并不直接地收到信号本身，而是收到一组特征向量$f$
\begin{equation}
    f=(f_0,\cdots,f_l)\qquad \forall 0\leq i\leq l,\ f_i\in F_i
\end{equation}
当中的分量表示由这一信号引起的具体的刺激。因此，所谓的特征是对发送者在发送信号时具体表现的进一步切分，它们表示接收者可能会注意到的各类表现，例如发送者此时的肢体语言、物理状态和发出的声响等等。我们姑且将特征理解为不同的感官刺激，但这并不是必要的，建模者完全可以选择别的划分方式。不过应该注意划分特征的一个重要原则：我们应当根据接收者自身的生物机制出发，将外界刺激分成可以被近似视作能够孤立地被感受到的几个类别。

可以想见发送者每次发出信号时的表现并不相同，例如猴子在发出每次警报声时的肢体动作不尽相同，声调并不完全一致。因此，信号通常并不唯一地与特征向量联系起来，而是以特定的概率$\text{P}(f_i/s_j)$决定此次发出信号时接收者感知到的特征向量。此外，发送信号时的发送者与接收者之间的距离、不同的环境状态等因素也会影响接收者收到的特征，它们的作用也可以表征到这一概率之中。当信号确定地触发某一特征时，即$\text{P}(f_i/s_j)=1$时，赫尔曼等人称此特征为这一信号的信号特征（signal-feature）。另一极端则是信号完全随机地触发某一类特征，即
\begin{equation}
    \text{P}(f_i/s_j)= \frac{1}{|F_i|}\qquad \forall f_i\in F_i
\end{equation}
其中$|F_i|$为特征$F_i$内具体特征的数量。称此类特征为非相关特征（uncorrelated feature），因为它没有反映任何有关于此信号发出与否的信息。当然，更常见的情况可能是信号与特征有一定的联系，但并不像信号特征一样具有确定的联系，称此类特征为相关特征（correlated feature）。此外，信号和特征之间的相关性还可以用特征和信号的互信息来描述：
\begin{equation}
    I(F,S)=\sum_{s} \sum_{f}\text{P}(f,s) \log(\frac{\text{P}(f,s)}{\text{P}(f)\text{P}(s)})
\end{equation}
赫尔曼等人的工作演示了当只有一种特征时，这一特征与信号之间的互信息和博弈者的成功率有非常高的相关性；而当有多种特征时，对应着更高互信息的信号最受青睐。\cite{attention}他们的结果提示了互信息与注意力博弈的紧密联系，似乎博弈者总是会将互信息最大化以提高信号交流的可靠性。我将在第三节进一步发展他们的想法，利用信息概念讨论多模态信号在信号交流上的优势，并阐明注意力博弈如何能够让博弈双方提高信号系统的稳健性。

总而言之，一次注意力博弈涉及以下过程：（1）发送者观察到自然状态$\sigma_i$后根据当前策略选择发送信号$s_j$，（2）信号$s_j$以给定的概率分布触发一个特征向量$f$，（3）接收者依据策略注意到特征向量中的某个分量，（4）接收者根据当前策略与注意到的特征选择做出反应，（5）最后，若接收者的行为与当前状态相匹配，则双方都获得收益$1$，否则收益为零。

最后，我想讨论一下本文标题中“注意力机制”的涵义。在机器学习领域，巴赫达瑙等人将注意力机制引入神经机器翻译（Neural Machine Translation）中，使得模型能够动态聚焦于输入语句的不同部分，更加灵活地处理长句子，从而提高翻译准确度。\cite{attention_translation}他们的结果进一步被谷歌的科学家发展为Transformer架构，它完全抛弃了先前的循环神经网络和卷积神经网络的框架，转由多层自注意力（self-attention）和前馈神经网络构建编码器和解码器。\cite{attention_alluneed}这一成果直接使得注意力机制成为现代机器学习最具代表性的机制之一，Transformer架构也被广泛应用于自然语言处理以及其他模态的场景中。\cite{attention_vision}注意力机制在机器学习中最主要的功能在于有选择地聚焦于一部分最有价值的信息，加快计算效率的同时提高准确率。本文中所讨论的注意力机制也是如此，接收者通过不断的互动学习哪一部分特征是最有价值的，这一功能使它能够有效地识别信号并做出反应。但注意力机制并不仅仅出现在接收者身上，可以想象发送者也需要经过不断的学习掌握哪些自然界的特征最能反映自然状态，并对此做出反应。后者可以被整合进我们的讨论之中，但它对本文所讨论的话题没有太大的影响，因此我将聚焦于接收者的注意力机制。

\subsection{$2\times 2\times 2$模型的模拟}
我将通过最简单的$2\times 2\times 2$模型展示注意力博弈的具体机制和一些有趣的结果。假设共有两种等概率的自然状态$\sigma_0$和$\sigma_1$，两种信号$s_0$和$s_1$，以及两种行为$a_0$和$a_1$。除此之外还有$l+1$个二进制特征，其中每个特征都有$2$元素，分别为$0$和$1$，且$F_0$是信号特征，即当中的元素$0,1$分别与信号$s_0$和$s_1$确定地对应，其余的特征则是非相关特征。因此，每当发送者发出信号$s_i$，接收者会收到特征向量$f=(i,f_1,\cdots,f_l)$，特征$f_0$由信号决定，而其他非相关特征将随机给定。接收者只会注意到其中一个特征，并根据这一特征进行行动。

我将采用球罐学习模型（urn learning model）对上述模型进行模拟\footnote{本文所有的模拟都使用Python实现，相关的源代码和原始数据可从\url{https://github.com/EtonPhilo/Signal-Selection-and-Attention-Mechanism}获取。}，其中一个轮次的模拟如图1所示。发送者有两个球罐，分别对应两种自然状态。每个球罐内又有两类小球，分别对应两种信号。接收者有两组球罐，一是注意力球罐，其中的小球与特定特征相对应，二是不同特征对应的特征-行为球罐。我们称球罐内小球的数量为对应行为的倾向（propensity），在设定好初始的倾向之后开始迭代。首先等概率地选择两种状态$\sigma_0$和$\sigma_1$之一，然后发送者到对应状态的球罐中抽取小球，其上的标号决定了它要发送的信号。发送信号后，接收者依据概率收到一个特征向量，它首先从注意力球罐中抽出一个小球，然后根据小球的标号读取对应的特征分量，然后从对应的特征-行为球罐中抽取一个小球，根据其上的标号做出相应的行为。如果行为与状态相匹配，那么所有人都会获得一个与手上抽取到的小球一样的小球，否则它们什么奖励都没有。最后它们将所有抽取到的与奖励的小球放回原先的球罐里，完成这一轮游戏。接着如此往复，直到设定的迭代轮次。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/learning.pdf}
    \caption{强化学习模拟注意力博弈中一个轮次的流程。}
\end{figure}

我假设初始状态下所有罐中的各类小球都是一样多的，即发送者和接收者将会完全随机地进行互动。然后考虑特征总数从$1$到$5$的情形，分别进行$10^6$轮次的迭代，记录信号特征$F_0$的注意力占比的变化。将所有情形重复模拟$10^3$次取平均值，绘制出接收者对信号特征$F_0$的注意力占比在迭代中的变化如图2。

\begin{figure}[htbp] 
    \label{attention_feature}
  \centering
  \includegraphics[width=0.9\textwidth]{figure/222game_feature.png}  
  \caption{特征总数从$1$到$5$的情形中，接收者对信号特征（Feature 0）的注意力占比随迭代轮次的变化。每隔$10^3$次迭代记录一次数据，由$10^3$次模拟结果取平均得到数据点。}
\end{figure}

对于只有一个特征的情形，接收者自然只能注意信号特征，此时信号特征的注意力占比始终为$100\%$（如图2中蓝线所示）。由于信号特征与信号的一一对应关系，此时模型退化为标准的信号博弈。与之对照的是特征总数大于$1$的情形，初始状态下接收者对信号特征的注意力占比为$\frac{1}{l+1}$，其中$l+1$为特征总数。在所有情形中，随着迭代轮次的增加，对信号特征的注意力占比逐渐上升，这意味着接收者逐渐学习到特征$F_0$与信号之间的对应关系，并将更多的注意力投入到信号特征中。但特征总数更大的情形的注意力占比始终小于特征总数更小的情形，这是因为前者对信号特征的初始注意力占比小于后者，由此导致的“注意力涣散”使它落后于起跑线上。

赫尔曼和范德鲁宁使用相同的模型，展示了不同情形下累计成功率随迭代轮次增加的变化。\cite{attention}他们发现特征总数的增加显著地降低了累计成功率，并延缓了系统达到特定成功率目标的时间点。我此处的结果印证了他们的发现，正是因为接收者在面对更多的特征时，它对信号特征的注意力占比更小，所以它将更多的时间耗费在了非相关特征上，使得成功率下降、系统演化出信号系统的时间增加。

\section{注意力操纵}
巴雷特（Jeffrey A. Barrett）和斯基姆（Brian Skyrms）提出由生物日常决策自发组装出信号博弈的多种机制，其中一种机制被称为“感觉操纵”（sensory-manipulation）。\cite{Assemblying}在这种情形中，接收者事先建立了信号与行为之间的联系，将信号博弈简化为发送者如何逐渐学会利用接收者的行为模式，在特定的状态下发出合适的信号，使得接收者做出正确的反应。例如某类的雌性青蛙会被特定的叫声所吸引，同种群的雄性青蛙则会逐渐学会发出这种叫声，吸引雌蛙前来交配。不同种群的雌蛙有着不同的偏好，而同种群的雄蛙总会演化出相应的求偶信号。\cite{frog}感觉操纵机制解释了这一现象：不同种群中的雄蛙利用该种群中雌蛙对特定声音的偏好，进一步将这一声音信号“仪式化”（ritualize）为求偶信号。

上述机制存在一点不足。雌蛙并不一定本能地将特定叫声与寻找配偶联系起来，而是由于如觅食、躲避天敌等其他场景的需要经演化或后天学习获得对特定叫声更强的敏感度，因此更容易注意到此类叫声。雄性信号则利用了雌性对这一刺激的高敏特性，吸引雌性的注意并激发其求偶行为。但若因此放弃叫声信号与求偶行为之间的预先联系，模型又将回到标准的信号博弈中，无法解释为何雄蛙总能将将高敏刺激仪式化为求偶信号。

注意力博弈正好可以解决这一点。特定信号系统总能形成意味着博弈机制的不对称性，正如前文所述，这种不对称性既不来源于信号与状态的联系，也不来源于信号与行为之间的联系，它必定来自于其他的机制，例如初始条件下注意力占比的不对称。假定雌蛙在初始状态下对听觉特征具有更高的注意力，与此特征联系的叫声信号因而具有先发优势，而不断的强化学习会放大这一优势，使种群总是将这类信号固定为求偶信号。我将这类不均匀的注意力分布称为“注意力偏好”（attention bias），如果将特征理解为不同类型的感觉刺激，它可以被诠释为“感官偏好”（sensory bias）。

类似的不对称性还可能来源于更新机制的不对称。设想一类生物对某类特征有更强的学习能力，在注意到此类特征并做出合适的行动时，它会给这类特征以更大的奖励；又或者某类特征对这类生物更难以察觉，它们需要耗费更多的注意力资源和识别时间，这也会导致最终获得的奖励不如其他特征。在迭代中，给予更高奖励的特征具有累积优势，在不断的博弈更快地提高对应的注意力倾向，形成后天的注意力偏好，我将这类机制称为差异化奖励。当然，生物体完全可能同时具有注意力偏好和差异化奖励两种机制，其相互影响可能更加复杂，但在这里我只分析两种机制各自对信号系统演化的影响。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/attention_manipulation.png}
    \caption{两种情形中对特征$F_0$的注意力的变化和偶数标号的信号$s_0$与$s_2$的发送概率变化。蓝线表示注意力偏好的情形，橙线表示差异化奖励的情形；实线表示注意力占比，虚线表示偶数标号的信号的发送概率。每条线均由$10^3$次模拟取平均值得到。}
\end{figure}

考虑一个$2\times 4\times 2$注意博弈模型，即有两种状态，四种信号和两种行为。有两类二进制特征，其中$F_0$为偶数标号的信号$s_0$和$s_2$的信号特征，$F_1$为非相关特征；而对于奇数标号的信号$s_1$和$s_3$则反之。设计两种情形，一是初始状态下接收者对特征$F_0$的注意力倾向为$10$，对$F_1$的倾向为$1$，这表示注意力偏好的情况；二是初始状态下注意力分布均匀，而接收者在注意到特征$F_0$并做出正确行为时，对特征$F_0$的注意力倾向会增加$2$，而注意到特征$F_1$并成功时只奖励$1$，这表示差异化奖励的情况。正如前面的分析，接收者更有可能注意偶数标号的信号对应的信号特征，因此总会利用偶数标号的信号传递信息。利用计算机模拟，记录接收者对特征$F_0$注意力占比和偶数标号的信号的理论发送概率\footnote{理论发送概率指的是根据当前发送者所采取的策略，它发出偶数标号的信号的期望概率$\text{P}(\text{even signals})=\sum_i(\text{P}(s_0/\sigma_i)\text{P}(\sigma_i)+\text{P} (s_2/\sigma_i)\text{P}(\sigma_i))$。}并绘于图3，可以看出两种情形都会导致对特征$F_0$占据主要的注意力，且不对称的初始条件和更新机制都会使得偶数标号的信号更常被使用，博弈者总会利用它们进行进行交流。

上述机制可以视作对感觉操纵的推广：特定的信号不再直接地与特定行为联系，而仅是更能引起接收者的注意，使其更有可能做出正确反应。因此我将其称为“注意力操纵”，意指在博弈过程中，发送者会逐渐利用接收者注意力的初始分布不均或发展差异，强化更容易引起注意的信号的使用率，并以此为基础搭建信号系统。不同于感觉操纵的是，信号系统的约定性（conventionality）依旧存在，例如自然$\sigma_0$时既可以与$s_0$联系，也可以与$s_2$联系，因为这二者之间的对称性没有破除。但这些信号所具备的基于接收者注意力机制的优势，令它们从一众信号中脱颖而出，我们也因此得到了一个关于信号选择的演化博弈论解释。

\section{多模态信号与基于信息量的信号选择}
近来许多的研究指出动物之间的交流通常是多模态的（multimodal），即信号本身可以分为多个具有不同物理特性的部分，且它的接收涉及多个感觉系统。\cite{multimodal}一个经典的例子是一类跳蛛，其中的雄性个体会在求偶时跳一种非常特别的“舞蹈”：它们会轻快且有节奏地抖腿，同时利用腹部的颤动使地面产生微小的震动。相关的研究分析跳蛛的舞蹈是“自由”多模态信号，因为雄性跳蛛的求偶舞与震动是两个独立的过程，跳蛛完全可以选择只跳舞或只产生小震动。\cite{spider}这类信号区别于“固定”多模态信号，例如人类的语言信号，发出的语音总不可避免地伴随嘴唇的运动。一个自然的问题是，既然单模态信号也能传输信息，“自由”多模态信号为什么会被广泛使用呢？这样多此一举的行为可能被解释为同时使用两个独立的传输通道能够降低信号传输失败的可能性，从而提高信号交流的稳健性。威尔逊（Alistair J. Wilson）等人建立了一个多模态交流的博弈论模型，分析了损耗函数、带宽和噪声等因素对博弈过程的影响，指出多模态信号确实在许多不同情况下更受青睐。\cite{multi_game}仅从信号系统的稳健性考量，如果发送者能够选择使用多模态信号与单模态信号，似乎发送多模态信号总是一个更好的选择。

但事情远非那么简单，正如我们将在下面的分析中看到，考虑到信号传输特性的不同，它们可能含有的不同噪声量，因此多模态信号并不总是意味着更高的信息量，单模态信号也不总是更不可靠。注意力博弈为我们提供了一个非常适合描述多模态信号的模型，其中的不同特征便可以诠释为不同的感官通道，而信号触发特定特征的概率则对应信号在该感官通道上的传输成功率。在这一诠释下，多模态信号是具有多种相关特征的信号，而单模态信号则只具有一种相关特征。我将在注意力博弈的框架下讨论多模态信号与单模态信号的选择问题，并指出信号的使用率实际上取决于信号所携带的信息量。

设想一个$2\times 3\times 2$信号博弈模型，其中有两种状态，三种信号和两种行为。此外还有两种二进制特征$F_0$和$F_1$，它们分别对应着视觉特征和听觉特征。将信号$s_0$理解为阴性信号，即发送者什么也没有做，它可以$100\%$地触发特征向量$(0,0)$。而$s_1$是一个多模态信号，同时涉及视觉特征与听觉特征。由于障碍物的阻挡或光线条件的不足，接收者只有$a$的概率收到视觉刺激$f_0=1$；而由于恶劣天气等因素的影响，接收者只有$b$的概率收到相应的听觉刺激$f_1=1$；由于这两种特征在物理特性上的差异，我们可以假定这它们各自的传输成功为独立事件。作为对比，$s_2$是一个单模态信号，它只涉及视觉特征，暂且设定其成功触发$f_0=1$的概率也为$a$，同时，听觉刺激是它的不相关特征。

接下来进行模拟。我将$(a,b)$可能的取值范围定为$[0.5,1]\times [0.5,1]$，然后将每个坐标轴平均分为$20$份，由此划定$400$个小方格，由小方格的中心点处的值作为采样值进行模拟。记录每个采样点处在$10^4$次迭代后信号$s_1$与信号$s_2$的理论使用率之差，绘制成热力图如图4。可以看出在$b\approx 0.5$时，两种信号的使用率差异很小，这是因为信号$s_1$的听觉刺激传输成功率很低，接近于$s_2$的随机触发。然而，随着$b$的提高，$s_1$与$s_2$的使用率差距逐渐增大，这是因为随着听觉信号的传输成功率的上升，$s_1$作为多模态信号的优势逐渐体现出来。通过增加传输通道，$s_1$即使在视觉刺激上传输失败，也能通过听觉刺激传输信息，因此具有比$s_2$更强的稳健性。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{figure/multifeat.png}
    \caption{信号$s_1$和信号$s_2$的理论使用率之差（热力图）以及其信息量之差（等高线图），横纵坐标分别对应信号在视觉通道上和听觉通道上的传输成功率$a$和$b$。每个采样点进行$10^4$次迭代，重复$10^4$次对数据取平均值。}
\end{figure}

我们还可以利用信息概念对图中变化进行更细致的定量分析。如前文所述，信号与特征之间的互信息描述了特征向量所包含的关于信号的平均信息量，其中某一信号$s$对互信息的绝对贡献为：
\begin{equation}
    I(F,\text{signal}=s)=\sum_f \text{P}(f,s)\log (\frac{\text{P}(f,s)}{\text{P}(f)\text{P}(s)})
\end{equation}
如图4，我将信号$s_1$与$s_2$的绝对贡献相减，以等高线的形式绘制在取值空间中。可以看出，两个信息量之差的变化与其使用率之差的变化非常类似。\footnote{读者可能会质疑这一结果的意义，因为互信息的计算不可避免地涉及信号的使用率，而我又将其与信号使用率进行比较，似乎由此陷入了一个自指的循环。但这并没有将我的发现平凡化，因为并不是所有可能的信号使用率都与其对应的互信息有如此类似的变化，只有演化到一个稳定的状态才有此现象。稳定状态类似于互信息函数的不动点，它使得信号使用率与由此计算得出的互信息成正比$\text{P}(s)\propto I(F,\text{signal}=s)$。}这是因为在博弈过程中，强化学习总是将双方引向局部最优的策略，而在信号使用率与信号量之间成正比时，系统达到了局部最优的信号发送策略，即令使用频率与其能够传递的信息量相匹配。若一个信号能够携带更多的信息量，那么这个信号的使用频率就会相应地提高。因此，我们能使用信息量的概念定量地解释图中更细节的变化。例如，在左上角，即$a\approx  0.5$而$b\approx 1$的部分，信号$s_2$对于两种刺激的触发成功率都很低，而信号$s_1$通过听觉刺激极高的成功率有效地传输信息，因此有更高的使用率。随着$a$的上升，$s_2$所携带的信息量也随之上升，$s_1$的优势逐渐消失，而$s_2$的使用率便因此逐渐上升。

\begin{figure}[htbp]
  \centering
  \begin{minipage}[t]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figure/multifeat_diff+0.2.png}
    \caption{$\Delta=0.2$时两个信号使用率之差和信息量之差。每个采样点进行$10^4$次迭代，重复$10^4$次对数据取平均值。}
    \label{fig:img1}
  \end{minipage}
  \hfill
  \begin{minipage}[t]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figure/multifeat_diff-0.2.png}
    \caption{$\Delta=-0.2$（当$a+0.2>1$时取$a'=1$）时两个信号使用率之差和信息量之差。每个采样点进行$10^4$次迭代，重复$10^4$次对数据取平均值。}
    \label{fig:img2}
  \end{minipage}
\end{figure}

前文的模拟将$s_2$对视觉刺激的触发概率$a'$设置为与$s_1$相同的值，因此$s_1$的信息量总是高于$s_2$。我们可以考虑其他的情况，例如$\Delta = a-a'$为一恒定值的情形。如图5和图6所示，我分别对$\Delta=0.2$和$-0.2$的情形进行模拟并记录了两个信号使用率之差和信息量之差，使用率与信息量依旧吻合得非常好。当$\Delta=0.2$时，信号$s_2$总是劣于$s_1$，不过随着$a$的增大两者之间的差距逐渐缩小。有趣的是当$\Delta=-0.2$时，信号$s_2$对视觉刺激的成功率要高于$s_1$，因此在$b$比较小时信号$s_2$实际上要优于作为多模态信号的$s_1$。但是随着$b$的上升，多模态信号的优势逐渐凸显，并在$b\gtrsim 0.8$时优于单模态信号\footnote{在$b$不变的情况下，随着$a$的变化，信息量之差在$a=0.8$处有一个最小值。这是因为在$a<0.8$时，信号$s_2$对视觉刺激的传输成功率总是比$s_1$大$0.2$，由于信息量是一个凸函数，随着$a$上升二者差距不断增大。而在$a>0.8$之后，由于$a'$只能取恒定值$1$，随着$a$增加$a'$不再变化，因此信号$s_2$的信息量保持不变，而$s_1$的信息量依旧上升，使得信息量之差增大。}。

因此，我们可以看出多模态信号并不会因为具有更多的传输通道就总是优于单模态信号。相比于不同信号所能触发的特征数量，更为重要的是它们触发这些特征的成功率以及由此决定的信息量。在信号博弈中，发送者会基于信号携带的信息量进行使用率分配，而分配的最终结果是将信号传输的稳健性达到局部最优。

\section*{结论}
在本文中，我采用赫尔曼和范德鲁宁提出的注意力博弈，讨论了信号博弈中不同信号的选择问题。我介绍了由注意力机制引入的两类不对称性，分别是接收侧的不对称性，它来自接收者注意力资源分布不均；以及发送侧的不对称性，它来自于由信号本身性质决定的发送成功率。我展示了这两种机制中，发送者都会利用这一不对称性，发送合适的信号以提高信号系统的效率和稳健性。对于第一类不对称性，发送者会利用接收者注意力资源分配的不均等，更倾向于发送更能吸引注意力的信号。而对于第二类不对称性，发送者会利用信号本身的传输成功率，将信号使用率依据其能携带的信息量进行分配。通过本文的研究，我将信号选择归为演化博弈的结果，在不预设更高程度的理性的前提下，无论存在那种不对称性，信号博弈中的双方都能通过演化博弈的机制，发展出更能提高信号交流效率和可靠性的信号系统。

本文的工作拓宽了注意力博弈的应用，并引入更多尚待研究的话题。例如，我在本文中保留赫尔曼等人的设定，假设接收者只能选择接收一种特征，但现实中的动物不太可能遵循这一原则，而是将注意力资源分配至多个特征，甚至为来自不同特征的刺激分配不同的权重以决定最终的反应。进一步的研究可以采用平均场（mean field）技术，将离散化的强化学习过程变换到一个类似于复制子动力学的平均场理论，此时接收者可以分配注意力资源实现对多个特征的关注，最终的行为则需要依据注意力分布对行为倾向加权后再进行选择。\cite{mean_field}其二，我在本文中没有考虑注意力可能造成的效用损耗。当动物将更多的注意力投入到对信号的探测时，它会提高信号的识别效率和准确性，但同时它也可能会因为没有保持足够的警惕而收到伤害。或许可以给注意力分配加入类似王济东和张明君所采用的感知成本机制，当发送者将更多的注意力分配到信号识别中时，它必须平衡由此带来的风险和效益。\cite{Zhang}这一新的机制加入或许会引入更多有趣的现象，还能够帮助我们更加全面地分析信号选择以及其他问题。最后，我在第三节中对互信息和信号使用率的讨论尚不成熟，未来的工作可以专注于分析二者在数学上的联系，进一步探索信息量对信号选择的影响。

\begin{comment}
\section{刘易斯-斯基姆信号博弈}
刘易斯（David K. Lewis）最早提出了信号博弈，其中的发送者和接收者利用预先存在的显著性（saliences）协调双方的行为，构建出一个约定的信号系统。\cite{Lewis}如果发送者能在各种自然状态下发送特定的信号，使得接收者在收到信号后做出正确反应，那么双方都会收到一定的回报，否则没有回报。在这一的状态下，任意一方偏离当前策略都会导致接收者做出错误反应，使得回报减少。斯基姆（Brian Skyrms）进一步指出在这一的回报设定下，信号系统可以通过演化博弈论的机制从混乱中产生\cite{Skyrms game}。

让我们考虑最简单的$2\times 2\times 2$模型，当中共有两种等概率的自然状态$\sigma_0$和$\sigma_1$，两种信号$s_0$和$s_1$，以及两种行为$a_0$和$a_1$。发送者的策略可以表征为在各个自然状态下发送某个信号的概率：
\begin{equation*}
    \text{P}(s_i/\sigma_j)\qquad i,j=0,1
\end{equation*}
同理，接收者的策略为在接收到各个信号的条件下做出某个行为的概率。如果在自然状态为$\sigma_i$时接收者做出行为$a_i$，那么双方都会收到回报$1$，否则回报为$0$。假定发送者和接收者分属两个种群\footnote{当然，也可以假定个体可以同时扮演发送者和接收者，但为了保持与后文的连贯性，我们只讨论二者分属两个种群的情形。}，它们只会与对方种群的个体博弈，且在给定的策略下，它们的回报函数由下式给出：
\begin{equation}
    w_{\text{sender}}=w_{\text{receiver}}=\sum_{i=0}^1 \text{P}(a_i,\sigma_i)=\sum_{i=0}^1\sum_{j=0}^1\text{P}(a_i/s_j)\text{P}(s_j/\sigma_i)\text{P}(\sigma_i)=\frac{1}{2}\sum_{i=0}^1\sum_{j=0}^1\text{P}(a_i/s_j)\text{P}(s_j/\sigma_i)
\end{equation}
这些数学上的设定构成了对信号博弈模型的形式化，我们接下来便可以利用演化博弈论的相关工具对它进行分析，但更为便捷是采用强化学习进行模拟。

\section{强化学习}
演化博弈论并不是唯一用于分析信号博弈模型的方法，许多学者采用强化学习的方法，利用计算机模拟分析模型的演化。\cite{Skyrms info,syntactic,saliences}强化学习不再处理种群中的策略分布，而是表征一对博弈者，在不断的互动中调整它们的策略，从而“学习”使用最佳的应对策略。

强化学习有非常多的实现方式，在这里我以球罐学习模型（Urn Learning Model）为例阐明强化学习的基本思想。每个智能体都有一个球罐，里面有一定数量的小球，每个小球上都有标号$i$对应一个特定的行为$i$。我们称带有$i$标号的小球的数量为该智能体对$i$行为的“倾向”（propensity），记为$q_i$。在第$t$轮中，智能体都会从球罐中随机抽取一个小球，根据小球上的标号来行动。因此，它选择$i$行为的概率由当时的倾向决定：
\begin{equation}
    \text{p}_i(t)=\frac{q_i(t)}{\sum_i q_i(t)}
\end{equation}
在抽取完成后，智能体会依据做出的行为获得若干奖励$w_i$，它会把抽到的小球放回球罐并额外往球罐内增加$n$个带$i$标号的小球，这被称为倾向的更新：
\begin{equation}
    q_i(t+1)=q_i(t)+w_i
\end{equation}
在初始条件下，往球罐内放置特定组合的小球，这一组合就决定了智能体的初始概率。然后我们让智能体进行抽取小球的游戏，并根据抽取到的标号更新倾向，如此迭代一定轮次。不难想象随着轮次的增加，对应更多奖励的小球会增加地比其他标号的小球更快，这又反过来导致智能体更有可能选到这类小球，进而获得更多奖励。强化学习的结果就是智能体演化出了特定的倾向，使得它能够最大化奖励。

将强化学习的模型应用到信号博弈中，我们分别有一个对应自然状态的球罐，其中有两类等量的小球分别对应$\sigma_0$和$\sigma_1$两种状态，它不会更新，一直保持两类小球等量的分布。此外，发送者有两个球罐，分别对应两种自然状态。每个球罐内又有两类小球，分别对应两种信号。类似的，接收者也有两个球罐，分别对应两种信号，每个球罐有两类分别对应两种行为的小球。设定好初始的小球数量之后开始游戏，我们从自然状态的球罐中选取一个小球，其上的标号就是当前的状态。然后，发送者到对应状态的球罐中抽取小球，其上的标号决定了它要发送的信号。接收者收到信号后到对应信号的球罐抽取小球，根据其上的标号做出行为。如果行为与当前状态相对应，那么将发送者和接收者都会收到奖励，它们将会额外获得一个与目前手上的小球完全相同的小球，否则它们什么奖励都没有。最后将抽取的和奖励的小球放回对应的罐中，结束这一轮游戏。我们将会在下一节看到，发送者和接收者会在这一过程中逐渐“学会”使用信号并对信号做出正确反应。由于它在计算机模拟上的便利性，这也将是本文中所有模型的分析方法。
\end{comment}

% 在此部分总结主要研究发现、理论意义及可能存在的不足，提出后续研究方向。

% -------------------------------
% 参考文献：请使用中文社科论文常见引用格式
% 如果采用 BibTeX 方式，请使用如下两种常见样式之一：
%   \bibliographystyle{gbt7714-numerical}  或  \bibliographystyle{gbt7714-author-year}
%
% 本示例采用手写参考文献环境

\begin{thebibliography}{99}
\renewcommand{\baselinestretch}{1.0}  % 参考文献部分一般使用单倍行距
\bibitem{Lewis} Lewis, David Kellogg. \textit{Convention: A Philosophical Study} [M]. Cambridge, MA, USA: Wiley-Blackwell, 1969.

\bibitem{Skyrms game} Skyrms, B. \textit{Evolution of the Social Contract} [M]. Cambridge University Press, 1996.

\bibitem{Skyrms info} Skyrms, B. \textit{Signals: Evolution, learning, \& information} [M]. Oxford University Press, 2010.

\bibitem{attention} Herrmann, Daniel A., VanDrunen, Jacob. Sifting the Signal from the Noise [J]. \textit{British Journal for the Philosophy of Science} (forthcoming).

\bibitem{attention_translation}  Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate [OL]. \textit{CoRR}, 2014, abs/1409.0473.

\bibitem{attention_alluneed} Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., Polosukhin, I. Attention is All You Need [C]. NeurIPS, 2017, \url{https://arxiv.org/abs/1706.03762}

\bibitem{attention_vision} Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Houlsby, N. An Image is Worth $16\times16$ Words: Transformers for Image Recognition at Scale [OL]. \textit{arXiv}, 2021, \url{https://arxiv.org/abs/2010.11929}.

\bibitem{Assemblying} Barrett, Jeffrey A., Skyrms, Brian. Self-assembling Games [J]. \textit{British Journal for the Philosophy of Science}, 2017, 68 (2):329-353.

\bibitem{frog} Ryan, M., Fox, J., Wilczynski, W. et al. Sexual selection for sensory exploitation in the frog \textit{Physalaemus pustulosus} [J]. \textit{Nature}, 1990, 343, 66-67.

\bibitem{multimodal} Higham, J.P., Hebets, E.A. An introduction to multimodal communication [J]. \textit{Behav Ecol Sociobiol}, 2013, 67, 1381–1388.

\bibitem{spider} DAMIAN O. ELIAS, WAYNE P. MADDISON, CHRISTINA PECKMEZIAN, MADELINE B. GIRARD, ANDREW C. MASON, Orchestrating the score: complex multimodal courtship in the Habronattus coecatus group of Habronattus jumping spiders (Araneae: Salticidae) [J], \textit{Biological Journal of the Linnean Society}, 2012, Volume 105, Issue 3, Pages 522–547.

\bibitem{multi_game} Wilson, A.J., Dean, M. \& Higham, J.P. A game theoretic approach to multimodal communication [J]. \textit{Behav Ecol Sociobiol}, 2013, 67, 1399–1415.

\bibitem{mean_field} Tuyls, K., Heytens, D., Nowe, A., Manderick, B. Extended Replicator Dynamics as a Key to Reinforcement Learning in Multi-agent Systems [C]. In: Lavrač, N., Gamberger, D., Blockeel, H., Todorovski, L. (eds) Machine Learning: ECML 2003. Lecture Notes in Computer Science(), vol 2837. Springer, Berlin, Heidelberg.

\bibitem{Zhang} Wang, J., Zhang, M. Solving the Partition Problem: Signaling Games and the Cost-Based Perception Model [J]. \textit{Erkenntnis}, 2025, \url{https://doi.org/10.1007/s10670-025-00979-9}.
% 其他类型参考文献请参照学校或期刊要求书写格式
\end{thebibliography}

% 若使用 BibLaTeX，则替换上述参考文献部分为：
% \printbibliography

\end{document}
